{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning and fine-tuning with pretrained ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual pipeline of a transfer-learning & fine-tuning workflow. See https://keras.io/guides/transfer_learning/.\n",
    "1. Append trainable layers to a pretrained foundation model.\n",
    "2. Freeze the base model, train the last layer until convergence.\n",
    "3. Unfreeze the base model, train the whole model with very small learning rate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45828 files belonging to 50 classes.\n",
      "Found 9438 files belonging to 50 classes.\n",
      "Found 9504 files belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "data_train = tf.keras.utils.image_dataset_from_directory(\"Processed_Split/train\", labels='inferred', image_size=(224, 224), batch_size=32)\n",
    "data_val = tf.keras.utils.image_dataset_from_directory(\"Processed_Split/val\", labels='inferred', image_size=(224, 224), batch_size=32)\n",
    "data_test = tf.keras.utils.image_dataset_from_directory(\"Processed_Split/test\", labels='inferred', image_size=(224, 224), batch_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the batch method to prepare batches.\n",
    "data_train = data_train.map(lambda x, y: (tf.keras.applications.resnet50.preprocess_input(x), y))\n",
    "data_val = data_val.map(lambda x, y: (tf.keras.applications.resnet50.preprocess_input(x), y))\n",
    "data_test = data_test.map(lambda x, y: (tf.keras.applications.resnet50.preprocess_input(x), y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 50\n",
    "\n",
    "inputs = layers.Input(shape=(224, 224, 3))\n",
    "resnet = keras.applications.resnet50.ResNet50(include_top=False, weights=\"imagenet\")\n",
    "resnet.trainable = False\n",
    "x = resnet(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=\"accuracy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training (freeze ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1433/1433 [==============================] - 173s 117ms/step - loss: 0.5176 - accuracy: 0.8516 - val_loss: 0.3121 - val_accuracy: 0.9077 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "1433/1433 [==============================] - 169s 117ms/step - loss: 0.2682 - accuracy: 0.9164 - val_loss: 0.2747 - val_accuracy: 0.9153 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "1433/1433 [==============================] - 157s 110ms/step - loss: 0.2133 - accuracy: 0.9317 - val_loss: 0.2603 - val_accuracy: 0.9199 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "1433/1433 [==============================] - 162s 113ms/step - loss: 0.1825 - accuracy: 0.9420 - val_loss: 0.2222 - val_accuracy: 0.9305 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "1433/1433 [==============================] - 160s 111ms/step - loss: 0.1570 - accuracy: 0.9496 - val_loss: 0.2292 - val_accuracy: 0.9290 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "1433/1433 [==============================] - 164s 114ms/step - loss: 0.1392 - accuracy: 0.9551 - val_loss: 0.2225 - val_accuracy: 0.9292 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "1433/1433 [==============================] - 165s 115ms/step - loss: 0.1108 - accuracy: 0.9663 - val_loss: 0.1928 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
      "Epoch 8/20\n",
      "1433/1433 [==============================] - 165s 115ms/step - loss: 0.1033 - accuracy: 0.9687 - val_loss: 0.1923 - val_accuracy: 0.9374 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "1433/1433 [==============================] - 165s 115ms/step - loss: 0.0978 - accuracy: 0.9708 - val_loss: 0.1912 - val_accuracy: 0.9397 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "1433/1433 [==============================] - 178s 124ms/step - loss: 0.0922 - accuracy: 0.9726 - val_loss: 0.1904 - val_accuracy: 0.9406 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "1433/1433 [==============================] - 163s 114ms/step - loss: 0.0875 - accuracy: 0.9749 - val_loss: 0.1978 - val_accuracy: 0.9379 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "1433/1433 [==============================] - 164s 114ms/step - loss: 0.0830 - accuracy: 0.9764 - val_loss: 0.1903 - val_accuracy: 0.9413 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "1433/1433 [==============================] - 163s 114ms/step - loss: 0.0786 - accuracy: 0.9776 - val_loss: 0.1929 - val_accuracy: 0.9411 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "1433/1433 [==============================] - 164s 114ms/step - loss: 0.0748 - accuracy: 0.9795 - val_loss: 0.1898 - val_accuracy: 0.9408 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "1433/1433 [==============================] - 164s 114ms/step - loss: 0.0666 - accuracy: 0.9826 - val_loss: 0.1835 - val_accuracy: 0.9439 - lr: 2.5000e-04\n",
      "Epoch 16/20\n",
      "1433/1433 [==============================] - 164s 115ms/step - loss: 0.0648 - accuracy: 0.9838 - val_loss: 0.1833 - val_accuracy: 0.9444 - lr: 2.5000e-04\n",
      "Epoch 17/20\n",
      "1433/1433 [==============================] - 159s 111ms/step - loss: 0.0628 - accuracy: 0.9844 - val_loss: 0.1833 - val_accuracy: 0.9442 - lr: 2.5000e-04\n",
      "Epoch 18/20\n",
      "1433/1433 [==============================] - 148s 103ms/step - loss: 0.0617 - accuracy: 0.9849 - val_loss: 0.1827 - val_accuracy: 0.9447 - lr: 2.5000e-04\n",
      "Epoch 19/20\n",
      "1433/1433 [==============================] - 145s 101ms/step - loss: 0.0601 - accuracy: 0.9855 - val_loss: 0.1833 - val_accuracy: 0.9443 - lr: 2.5000e-04\n",
      "Epoch 20/20\n",
      "1433/1433 [==============================] - 144s 100ms/step - loss: 0.0587 - accuracy: 0.9857 - val_loss: 0.1837 - val_accuracy: 0.9446 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode=\"max\", patience=4, verbose=1, baseline=0.0, restore_best_weights=True) # monitor validation loss, stop training if loss stops decreasing\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode=\"max\", factor=0.5, patience=2, min_lr=0.000003125)\n",
    "\n",
    "log = model.fit(x=data_train, epochs=20, validation_data=data_val, callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 25s 84ms/step - loss: 0.1845 - accuracy: 0.9447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: freeze_resnet/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: freeze_resnet/assets\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(data_test)\n",
    "model.save(\"freeze_resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_fixed_order = tf.keras.utils.image_dataset_from_directory(\"Processed_Split/test\", labels='inferred', image_size=(224, 224), batch_size=32, shuffle=False).map(lambda x, y: (tf.keras.applications.resnet50.preprocess_input(x), y))\n",
    "y_pred = model.predict(data_test_fixed_order)\n",
    "y_hat = np.argmax(y_pred, axis=1)\n",
    "y_true = np.concatenate([y for x, y in data_test_fixed_order], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9446548821548821\n",
      "Precision:  0.9449983750663737\n",
      "Recall:  0.9446548821548821\n",
      "F1:  0.9433189415173883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_hat))\n",
    "print(\"Precision: \", precision_score(y_true, y_hat, average='weighted'))\n",
    "print(\"Recall: \", recall_score(y_true, y_hat, average='weighted'))\n",
    "print(\"F1: \", f1_score(y_true, y_hat, average='weighted'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training (unfreeze ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1433/1433 [==============================] - 434s 300ms/step - loss: 0.1141 - accuracy: 0.9607 - val_loss: 0.1870 - val_accuracy: 0.9443 - lr: 1.0000e-05\n",
      "Epoch 2/10\n",
      "1433/1433 [==============================] - 423s 295ms/step - loss: 0.0628 - accuracy: 0.9786 - val_loss: 0.1858 - val_accuracy: 0.9484 - lr: 1.0000e-05\n",
      "Epoch 3/10\n",
      "1433/1433 [==============================] - 426s 297ms/step - loss: 0.0405 - accuracy: 0.9859 - val_loss: 0.1621 - val_accuracy: 0.9555 - lr: 1.0000e-05\n",
      "Epoch 4/10\n",
      "1433/1433 [==============================] - 427s 298ms/step - loss: 0.0319 - accuracy: 0.9896 - val_loss: 0.1648 - val_accuracy: 0.9575 - lr: 1.0000e-05\n",
      "Epoch 5/10\n",
      "1433/1433 [==============================] - 425s 297ms/step - loss: 0.0288 - accuracy: 0.9904 - val_loss: 0.1518 - val_accuracy: 0.9621 - lr: 1.0000e-05\n",
      "Epoch 6/10\n",
      "1433/1433 [==============================] - 421s 294ms/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.1561 - val_accuracy: 0.9612 - lr: 1.0000e-05\n",
      "Epoch 7/10\n",
      "1433/1433 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9985Restoring model weights from the end of the best epoch: 5.\n",
      "1433/1433 [==============================] - 427s 298ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.1733 - val_accuracy: 0.9602 - lr: 5.0000e-06\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "resnet.trainable = True\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=\"accuracy\")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode=\"max\", patience=2, verbose=1, baseline=0.0, restore_best_weights=True) # monitor validation loss, stop training if loss stops decreasing\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode=\"max\", factor=0.5, patience=1, min_lr=0.000003125)\n",
    "\n",
    "log = model.fit(x=data_train, epochs=10, validation_data=data_val, callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 27s 89ms/step - loss: 0.1389 - accuracy: 0.9638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet/assets\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(data_test)\n",
    "model.save('resnet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = tf.keras.models.load_model('resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 26s 87ms/step\n"
     ]
    }
   ],
   "source": [
    "data_test_fixed_order = tf.keras.utils.image_dataset_from_directory(\"Processed_Split/test\", labels='inferred', image_size=(224, 224), batch_size=32, shuffle=False).map(lambda x, y: (tf.keras.applications.resnet50.preprocess_input(x), y))\n",
    "y_pred = trained_model.predict(data_test_fixed_order)\n",
    "y_hat = np.argmax(y_pred, axis=1)\n",
    "y_true = np.concatenate([y for x, y in data_test_fixed_order], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9638047138047138\n",
      "Precision:  0.9640554083361087\n",
      "Recall:  0.9638047138047138\n",
      "F1:  0.962832199476148\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_hat))\n",
    "print(\"Precision: \", precision_score(y_true, y_hat, average='weighted'))\n",
    "print(\"Recall: \", recall_score(y_true, y_hat, average='weighted'))\n",
    "print(\"F1: \", f1_score(y_true, y_hat, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                 Amylax_triacantha     1.0000    0.5000    0.6667         4\n",
      "           Aphanizomenon_flosaquae     0.9765    0.9924    0.9844      1049\n",
      "       Aphanothece_paralleliformis     0.8333    1.0000    0.9091         5\n",
      "                             Beads     1.0000    1.0000    1.0000        20\n",
      "                      Centrales_sp     0.8625    0.9583    0.9079        72\n",
      "             Ceratoneis_closterium     0.8333    0.6250    0.7143         8\n",
      "                    Chaetoceros_sp     0.9700    0.9327    0.9510       208\n",
      "             Chaetoceros_sp_single     0.9697    0.9697    0.9697        33\n",
      "                    Chlorococcales     0.7857    0.7333    0.7586        15\n",
      "                     Chroococcales     0.9412    0.7273    0.8205        22\n",
      "                 Chroococcus_small     0.9535    0.9840    0.9685       125\n",
      "                           Ciliata     0.9714    0.9189    0.9444        37\n",
      "                   Cryptomonadales     0.9324    0.6389    0.7582       108\n",
      "           Cryptophyceae-Teleaulax     0.9463    0.9971    0.9710      1025\n",
      "      Cyclotella_choctawhatcheeana     0.9231    0.7500    0.8276        16\n",
      "        Cymbomonas_tetramitiformis     0.9032    0.9032    0.9032        31\n",
      "                       Dinophyceae     0.8930    0.8889    0.8910       216\n",
      "              Dinophysis_acuminata     1.0000    0.9118    0.9538        34\n",
      "       Dolichospermum-Anabaenopsis     0.9875    0.9859    0.9867      1842\n",
      "Dolichospermum-Anabaenopsis-coiled     0.9424    0.9549    0.9486       377\n",
      "                    Euglenophyceae     0.9333    0.8750    0.9032        16\n",
      "                   Eutreptiella_sp     0.9394    0.9172    0.9281       338\n",
      "                  Gonyaulax_verior     1.0000    0.7500    0.8571         4\n",
      "                     Gymnodiniales     1.0000    0.7273    0.8421        11\n",
      "                  Gymnodinium_like     0.8667    0.5200    0.6500        25\n",
      "             Heterocapsa_rotundata     0.9634    0.8495    0.9029        93\n",
      "             Heterocapsa_triquetra     0.9121    0.9919    0.9503       492\n",
      "                        Heterocyte     0.9730    0.9000    0.9351        40\n",
      "            Katablepharis_remigera     0.8333    0.5556    0.6667         9\n",
      "                     Licmophora_sp     1.0000    1.0000    1.0000        12\n",
      "                  Melosira_arctica     0.8750    1.0000    0.9333         7\n",
      "                   Merismopedia_sp     0.8571    0.7500    0.8000        16\n",
      "                 Mesodinium_rubrum     0.9195    0.9357    0.9275       171\n",
      "           Monoraphidium_contortum     0.9804    1.0000    0.9901        50\n",
      "                Nitzschia_paleacea     1.0000    1.0000    1.0000        11\n",
      "               Nodularia_spumigena     1.0000    0.6923    0.8182        26\n",
      "                       Oocystis_sp     0.9500    0.8976    0.9231       127\n",
      "                   Oscillatoriales     0.9970    0.9895    0.9932       666\n",
      "                Pauliella_taeniata     1.0000    1.0000    1.0000        19\n",
      "                 Pennales_sp_thick     1.0000    0.6875    0.8148        32\n",
      "                  Pennales_sp_thin     0.9194    0.9661    0.9421       118\n",
      "       Peridiniella_catenata_chain     1.0000    0.9667    0.9831        30\n",
      "      Peridiniella_catenata_single     0.9552    0.9412    0.9481       136\n",
      "             Prorocentrum_cordatum     0.9706    0.7857    0.8684        42\n",
      "                Pseudopedinella_sp     0.8852    0.9310    0.9076        58\n",
      "                    Pyramimonas_sp     0.9775    0.9405    0.9587       185\n",
      "               Skeletonema_marinoi     0.9904    0.9935    0.9919       620\n",
      "             Snowella-Woronichinia     0.9843    0.9932    0.9888       443\n",
      "           Thalassiosira_levanderi     0.9713    0.9738    0.9725       382\n",
      "                   Uroglenopsis_sp     1.0000    1.0000    1.0000        78\n",
      "\n",
      "                          accuracy                         0.9638      9504\n",
      "                         macro avg     0.9456    0.8781    0.9046      9504\n",
      "                      weighted avg     0.9641    0.9638    0.9628      9504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_hat, digits=4, target_names=sorted(os.listdir(\"Processed_Split/test\"))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
