{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning and fine-tuning with pretrained VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual pipeline of a transfer-learning & fine-tuning workflow. See https://keras.io/guides/transfer_learning/.\n",
    "1. Append trainable layers to a pretrained foundation model.\n",
    "2. Freeze the base model, train the last layer until convergence.\n",
    "3. Unfreeze the base model, train the whole model with very small learning rate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45828 files belonging to 50 classes.\n",
      "Found 9438 files belonging to 50 classes.\n",
      "Found 9504 files belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "data_train = tf.keras.utils.image_dataset_from_directory(\"Processed_Split/train\", labels='inferred', image_size=(224, 224), batch_size=32)\n",
    "data_val = tf.keras.utils.image_dataset_from_directory(\"Processed_Split/val\", labels='inferred', image_size=(224, 224), batch_size=32)\n",
    "data_test = tf.keras.utils.image_dataset_from_directory(\"Processed_Split/test\", labels='inferred', image_size=(224, 224), batch_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the batch method to prepare batches.\n",
    "data_train = data_train.map(lambda x, y: (tf.keras.applications.vgg16.preprocess_input(x), y))\n",
    "data_val = data_val.map(lambda x, y: (tf.keras.applications.vgg16.preprocess_input(x), y))\n",
    "data_test = data_test.map(lambda x, y: (tf.keras.applications.vgg16.preprocess_input(x), y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 50\n",
    "\n",
    "inputs = layers.Input(shape=(224, 224, 3))\n",
    "vgg = keras.applications.vgg16.VGG16(include_top=False, weights=\"imagenet\")\n",
    "vgg.trainable = False\n",
    "x = vgg(inputs, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=\"accuracy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training (freeze ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1433/1433 [==============================] - 253s 172ms/step - loss: 0.6654 - accuracy: 0.8225 - val_loss: 0.3539 - val_accuracy: 0.8958 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "1433/1433 [==============================] - 248s 173ms/step - loss: 0.2997 - accuracy: 0.9100 - val_loss: 0.2909 - val_accuracy: 0.9143 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "1433/1433 [==============================] - 244s 170ms/step - loss: 0.2383 - accuracy: 0.9268 - val_loss: 0.2754 - val_accuracy: 0.9170 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "1433/1433 [==============================] - 274s 191ms/step - loss: 0.2052 - accuracy: 0.9359 - val_loss: 0.2597 - val_accuracy: 0.9198 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "1433/1433 [==============================] - 245s 171ms/step - loss: 0.1830 - accuracy: 0.9425 - val_loss: 0.2576 - val_accuracy: 0.9212 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "1433/1433 [==============================] - 245s 170ms/step - loss: 0.1669 - accuracy: 0.9471 - val_loss: 0.2511 - val_accuracy: 0.9252 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "1433/1433 [==============================] - 246s 172ms/step - loss: 0.1526 - accuracy: 0.9516 - val_loss: 0.2557 - val_accuracy: 0.9230 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "1433/1433 [==============================] - 247s 172ms/step - loss: 0.1427 - accuracy: 0.9547 - val_loss: 0.2526 - val_accuracy: 0.9235 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "1433/1433 [==============================] - 247s 172ms/step - loss: 0.1213 - accuracy: 0.9624 - val_loss: 0.2371 - val_accuracy: 0.9288 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "1433/1433 [==============================] - 247s 172ms/step - loss: 0.1174 - accuracy: 0.9636 - val_loss: 0.2383 - val_accuracy: 0.9278 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "1433/1433 [==============================] - 246s 171ms/step - loss: 0.1135 - accuracy: 0.9650 - val_loss: 0.2367 - val_accuracy: 0.9281 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "1433/1433 [==============================] - 246s 171ms/step - loss: 0.1050 - accuracy: 0.9677 - val_loss: 0.2267 - val_accuracy: 0.9312 - lr: 2.5000e-04\n",
      "Epoch 13/20\n",
      "1433/1433 [==============================] - 246s 171ms/step - loss: 0.1028 - accuracy: 0.9693 - val_loss: 0.2263 - val_accuracy: 0.9303 - lr: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1433/1433 [==============================] - 245s 171ms/step - loss: 0.1011 - accuracy: 0.9700 - val_loss: 0.2269 - val_accuracy: 0.9311 - lr: 2.5000e-04\n",
      "Epoch 15/20\n",
      "1433/1433 [==============================] - 243s 169ms/step - loss: 0.0971 - accuracy: 0.9712 - val_loss: 0.2208 - val_accuracy: 0.9330 - lr: 1.2500e-04\n",
      "Epoch 16/20\n",
      "1433/1433 [==============================] - 242s 169ms/step - loss: 0.0961 - accuracy: 0.9716 - val_loss: 0.2204 - val_accuracy: 0.9330 - lr: 1.2500e-04\n",
      "Epoch 17/20\n",
      "1433/1433 [==============================] - 257s 179ms/step - loss: 0.0953 - accuracy: 0.9721 - val_loss: 0.2209 - val_accuracy: 0.9327 - lr: 1.2500e-04\n",
      "Epoch 18/20\n",
      "1433/1433 [==============================] - 248s 173ms/step - loss: 0.0934 - accuracy: 0.9727 - val_loss: 0.2187 - val_accuracy: 0.9332 - lr: 6.2500e-05\n",
      "Epoch 19/20\n",
      "1433/1433 [==============================] - 247s 172ms/step - loss: 0.0928 - accuracy: 0.9729 - val_loss: 0.2186 - val_accuracy: 0.9327 - lr: 6.2500e-05\n",
      "Epoch 20/20\n",
      "1433/1433 [==============================] - 252s 175ms/step - loss: 0.0925 - accuracy: 0.9731 - val_loss: 0.2187 - val_accuracy: 0.9334 - lr: 6.2500e-05\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode=\"max\", patience=4, verbose=1, baseline=0.0, restore_best_weights=True) # monitor validation loss, stop training if loss stops decreasing\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode=\"max\", factor=0.5, patience=2, min_lr=0.000003125)\n",
    "\n",
    "log = model.fit(x=data_train, epochs=20, validation_data=data_val, callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 42s 140ms/step - loss: 0.2285 - accuracy: 0.9314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: freeze_vgg1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: freeze_vgg1/assets\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(data_test)\n",
    "model.save(\"freeze_vgg1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9504 files belonging to 50 classes.\n",
      "297/297 [==============================] - 41s 139ms/step\n"
     ]
    }
   ],
   "source": [
    "data_test_fixed_order = tf.keras.utils.image_dataset_from_directory(\"Processed_Split/test\", labels='inferred', image_size=(224, 224), batch_size=32, shuffle=False).map(lambda x, y: (tf.keras.applications.vgg16.preprocess_input(x), y))\n",
    "y_pred = model.predict(data_test_fixed_order)\n",
    "y_hat = np.argmax(y_pred, axis=1)\n",
    "y_true = np.concatenate([y for x, y in data_test_fixed_order], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9313973063973064\n",
      "Precision:  0.9308454485922624\n",
      "Recall:  0.9313973063973064\n",
      "F1:  0.9306989786257014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_hat))\n",
    "print(\"Precision: \", precision_score(y_true, y_hat, average='weighted'))\n",
    "print(\"Recall: \", recall_score(y_true, y_hat, average='weighted'))\n",
    "print(\"F1: \", f1_score(y_true, y_hat, average='weighted'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training (unfreeze VGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1433/1433 [==============================] - 623s 432ms/step - loss: 0.1550 - accuracy: 0.9490 - val_loss: 0.2006 - val_accuracy: 0.9378 - lr: 1.0000e-05\n",
      "Epoch 2/10\n",
      "1433/1433 [==============================] - 601s 419ms/step - loss: 0.0776 - accuracy: 0.9739 - val_loss: 0.1712 - val_accuracy: 0.9518 - lr: 1.0000e-05\n",
      "Epoch 3/10\n",
      "1433/1433 [==============================] - 588s 410ms/step - loss: 0.0561 - accuracy: 0.9817 - val_loss: 0.1893 - val_accuracy: 0.9482 - lr: 1.0000e-05\n",
      "Epoch 4/10\n",
      "1433/1433 [==============================] - 572s 399ms/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 0.1667 - val_accuracy: 0.9606 - lr: 5.0000e-06\n",
      "Epoch 5/10\n",
      "1433/1433 [==============================] - 558s 389ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.2238 - val_accuracy: 0.9527 - lr: 5.0000e-06\n",
      "Epoch 6/10\n",
      "1433/1433 [==============================] - 592s 413ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.1529 - val_accuracy: 0.9704 - lr: 3.1250e-06\n",
      "Epoch 7/10\n",
      "1433/1433 [==============================] - 594s 414ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.1797 - val_accuracy: 0.9674 - lr: 3.1250e-06\n",
      "Epoch 8/10\n",
      "1433/1433 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9986Restoring model weights from the end of the best epoch: 6.\n",
      "1433/1433 [==============================] - 616s 429ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1780 - val_accuracy: 0.9651 - lr: 3.1250e-06\n",
      "Epoch 8: early stopping\n"
     ]
    }
   ],
   "source": [
    "vgg.trainable = True\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=\"accuracy\")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode=\"max\", patience=2, verbose=1, baseline=0.0, restore_best_weights=True) # monitor validation loss, stop training if loss stops decreasing\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode=\"max\", factor=0.5, patience=1, min_lr=0.000003125)\n",
    "\n",
    "log = model.fit(x=data_train, epochs=10, validation_data=data_val, callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 46s 153ms/step - loss: 0.1546 - accuracy: 0.9680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vgg1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: vgg1/assets\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(data_test)\n",
    "model.save('vgg1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = tf.keras.models.load_model('vgg1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9504 files belonging to 50 classes.\n",
      "297/297 [==============================] - 45s 151ms/step\n"
     ]
    }
   ],
   "source": [
    "data_test_fixed_order = tf.keras.utils.image_dataset_from_directory(\"Processed_Split/test\", labels='inferred', image_size=(224, 224), batch_size=32, shuffle=False).map(lambda x, y: (tf.keras.applications.vgg16.preprocess_input(x), y))\n",
    "y_pred = trained_model.predict(data_test_fixed_order)\n",
    "y_hat = np.argmax(y_pred, axis=1)\n",
    "y_true = np.concatenate([y for x, y in data_test_fixed_order], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.968013468013468\n",
      "Precision:  0.9680992533594471\n",
      "Recall:  0.968013468013468\n",
      "F1:  0.9677993098172192\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_hat))\n",
    "print(\"Precision: \", precision_score(y_true, y_hat, average='weighted'))\n",
    "print(\"Recall: \", recall_score(y_true, y_hat, average='weighted'))\n",
    "print(\"F1: \", f1_score(y_true, y_hat, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "                 Amylax_triacantha     1.0000    0.7500    0.8571         4\n",
      "           Aphanizomenon_flosaquae     0.9811    0.9924    0.9867      1049\n",
      "       Aphanothece_paralleliformis     0.8333    1.0000    0.9091         5\n",
      "                             Beads     1.0000    0.9500    0.9744        20\n",
      "                      Centrales_sp     0.9254    0.8611    0.8921        72\n",
      "             Ceratoneis_closterium     1.0000    0.7500    0.8571         8\n",
      "                    Chaetoceros_sp     0.9849    0.9423    0.9631       208\n",
      "             Chaetoceros_sp_single     0.9412    0.9697    0.9552        33\n",
      "                    Chlorococcales     0.7333    0.7333    0.7333        15\n",
      "                     Chroococcales     0.9333    0.6364    0.7568        22\n",
      "                 Chroococcus_small     0.9597    0.9520    0.9558       125\n",
      "                           Ciliata     0.8974    0.9459    0.9211        37\n",
      "                   Cryptomonadales     0.7870    0.7870    0.7870       108\n",
      "           Cryptophyceae-Teleaulax     0.9789    0.9941    0.9864      1025\n",
      "      Cyclotella_choctawhatcheeana     0.9286    0.8125    0.8667        16\n",
      "        Cymbomonas_tetramitiformis     0.8529    0.9355    0.8923        31\n",
      "                       Dinophyceae     0.9014    0.8889    0.8951       216\n",
      "              Dinophysis_acuminata     0.9706    0.9706    0.9706        34\n",
      "       Dolichospermum-Anabaenopsis     0.9885    0.9837    0.9861      1842\n",
      "Dolichospermum-Anabaenopsis-coiled     0.9455    0.9655    0.9554       377\n",
      "                    Euglenophyceae     0.8421    1.0000    0.9143        16\n",
      "                   Eutreptiella_sp     0.9459    0.9320    0.9389       338\n",
      "                  Gonyaulax_verior     1.0000    0.7500    0.8571         4\n",
      "                     Gymnodiniales     0.8182    0.8182    0.8182        11\n",
      "                  Gymnodinium_like     0.5500    0.4400    0.4889        25\n",
      "             Heterocapsa_rotundata     0.9255    0.9355    0.9305        93\n",
      "             Heterocapsa_triquetra     0.9659    0.9776    0.9717       492\n",
      "                        Heterocyte     0.9459    0.8750    0.9091        40\n",
      "            Katablepharis_remigera     0.7000    0.7778    0.7368         9\n",
      "                     Licmophora_sp     1.0000    1.0000    1.0000        12\n",
      "                  Melosira_arctica     0.6667    0.8571    0.7500         7\n",
      "                   Merismopedia_sp     0.8750    0.8750    0.8750        16\n",
      "                 Mesodinium_rubrum     0.9573    0.9181    0.9373       171\n",
      "           Monoraphidium_contortum     1.0000    1.0000    1.0000        50\n",
      "                Nitzschia_paleacea     1.0000    0.9091    0.9524        11\n",
      "               Nodularia_spumigena     0.9583    0.8846    0.9200        26\n",
      "                       Oocystis_sp     0.9449    0.9449    0.9449       127\n",
      "                   Oscillatoriales     0.9985    0.9910    0.9947       666\n",
      "                Pauliella_taeniata     1.0000    1.0000    1.0000        19\n",
      "                 Pennales_sp_thick     0.9091    0.9375    0.9231        32\n",
      "                  Pennales_sp_thin     0.9583    0.9746    0.9664       118\n",
      "       Peridiniella_catenata_chain     0.9667    0.9667    0.9667        30\n",
      "      Peridiniella_catenata_single     0.9338    0.9338    0.9338       136\n",
      "             Prorocentrum_cordatum     0.8367    0.9762    0.9011        42\n",
      "                Pseudopedinella_sp     0.8833    0.9138    0.8983        58\n",
      "                    Pyramimonas_sp     0.9888    0.9514    0.9697       185\n",
      "               Skeletonema_marinoi     0.9968    0.9935    0.9952       620\n",
      "             Snowella-Woronichinia     0.9778    0.9932    0.9854       443\n",
      "           Thalassiosira_levanderi     0.9613    0.9764    0.9688       382\n",
      "                   Uroglenopsis_sp     1.0000    0.9615    0.9804        78\n",
      "\n",
      "                          accuracy                         0.9680      9504\n",
      "                         macro avg     0.9210    0.9057    0.9106      9504\n",
      "                      weighted avg     0.9681    0.9680    0.9678      9504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_hat, digits=4, target_names=sorted(os.listdir(\"Processed_Split/test\"))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
