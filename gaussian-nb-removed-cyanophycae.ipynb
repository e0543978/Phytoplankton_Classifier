{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Gaussian Naive Bayes - removed cyanophycae"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Without preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('data/no_processing/train_100.csv', header=None)\n",
    "print(\"read train\")\n",
    "test_csv = pd.read_csv('data/no_processing/test_100.csv', header=None)\n",
    "print(\"read test\")\n",
    "validation_csv = pd.read_csv('data/no_processing/val_100.csv', header=None)\n",
    "print(\"read val\")\n",
    "Y_train = train_csv.iloc[:, -1]\n",
    "X_train = train_csv.iloc[:,:-1]\n",
    "X_test = test_csv.iloc[:,:-1]\n",
    "Y_test = test_csv.iloc[:, -1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_train.nunique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_val = validation_csv.iloc[:, :-1]\n",
    "Y_val = validation_csv.iloc[:, -1]\n",
    "y_to_remove = [18, 19, 1, 37, 47, 10, 35, 9, 31, 2]\n",
    "\n",
    "train_mask = np.isin(Y_train, y_to_remove, invert=True)\n",
    "X_train = X_train[train_mask]\n",
    "Y_train = Y_train[train_mask]\n",
    "\n",
    "test_mask = np.isin(Y_test, y_to_remove, invert=True)\n",
    "X_test = X_test[test_mask]\n",
    "Y_test = Y_test[test_mask]\n",
    "\n",
    "val_mask = np.isin(Y_val, y_to_remove, invert=True)\n",
    "X_val = X_val[val_mask]\n",
    "Y_val = Y_val[val_mask]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.fit_transform(X_test)\n",
    "scaler.fit_transform(X_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "\n",
    "cv_method = RepeatedStratifiedKFold(n_splits=3,\n",
    "                                    n_repeats=1,\n",
    "                                    random_state=999)\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "params_NB = {'var_smoothing': np.logspace(0, -9, num=30)}\n",
    "model = GaussianNB()\n",
    "\n",
    "gs_NB = GridSearchCV(estimator=model,\n",
    "                     param_grid=params_NB,\n",
    "                     cv=cv_method,\n",
    "                     verbose=1,\n",
    "                     scoring='f1_micro')\n",
    "\n",
    "Data_transformed = PowerTransformer().fit_transform(X_test)\n",
    "\n",
    "gs_NB.fit(X_train, Y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gs_NB.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gs_NB.best_score_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# gs_NB.fit(X_train, Y_train)\n",
    "gs_NB.fit(X_train, Y_train)\n",
    "Y_pred = gs_NB.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred, zero_division=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ensembling - Bagging"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "base_model = GaussianNB()\n",
    "ensemble_model = BaggingClassifier(estimator=base_model, n_estimators=10)\n",
    "\n",
    "ensemble_model.fit(X_train, Y_train)\n",
    "ensemble_model.fit(X_val, Y_val)\n",
    "Y_bag_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test, Y_bag_pred, zero_division=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ensembling - Boosting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "base_model = GaussianNB()\n",
    "ensemble_model = AdaBoostClassifier(estimator=base_model, n_estimators=10)\n",
    "\n",
    "ensemble_model.fit(X_train, Y_train)\n",
    "ensemble_model.fit(X_val, Y_val)\n",
    "Y_boost_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test, Y_bag_pred, zero_division=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## With PCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca_train_csv = pd.read_csv('data/pca/train_pca_100.csv', header=None)\n",
    "print(\"read pca_train\")\n",
    "pca_test_csv = pd.read_csv('data/pca/test_pca_100.csv', header=None)\n",
    "print(\"read pca_test\")\n",
    "pca_validation_csv = pd.read_csv('data/pca/val_pca_100.csv', header=None)\n",
    "print(\"read pca_val\")\n",
    "Y_pca_train = pca_train_csv.iloc[:, -1]\n",
    "X_pca_train = pca_train_csv.iloc[:,:-1]\n",
    "X_pca_test = pca_test_csv.iloc[:,:-1]\n",
    "Y_pca_test = pca_test_csv.iloc[:, -1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_pca_train.nunique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_pca_val = pca_validation_csv.iloc[:, :-1]\n",
    "Y_pca_val = pca_validation_csv.iloc[:, -1]\n",
    "\n",
    "X_pca_val.drop(X_pca_val.tail(1).index, inplace=True)\n",
    "Y_pca_val.drop(Y_pca_val.tail(1).index, inplace=True)\n",
    "print(X_pca_val)\n",
    "y_to_remove = [18, 19, 1, 37, 47, 10, 35, 9, 31, 2]\n",
    "\n",
    "train_mask = np.isin(Y_pca_train, y_to_remove, invert=True)\n",
    "X_pca_train = X_pca_train[train_mask]\n",
    "Y_pca_train = Y_pca_train[train_mask]\n",
    "\n",
    "test_mask = np.isin(Y_pca_test, y_to_remove, invert=True)\n",
    "X_pca_test = X_pca_test[test_mask]\n",
    "Y_pca_test = Y_pca_test[test_mask]\n",
    "\n",
    "val_mask = np.isin(Y_pca_val, y_to_remove, invert=True)\n",
    "X_pca_val = X_pca_val[val_mask]\n",
    "Y_pca_val = Y_pca_val[val_mask]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit_transform(X_pca_train)\n",
    "scaler.fit_transform(X_pca_test)\n",
    "scaler.fit_transform(X_pca_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import time\n",
    "st = time.time()\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "\n",
    "cv_method = RepeatedStratifiedKFold(n_splits=4,\n",
    "                                    n_repeats=3,\n",
    "                                    random_state=999)\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=5000)}\n",
    "pca_model = GaussianNB()\n",
    "\n",
    "gs_NB = RandomizedSearchCV(estimator=pca_model,\n",
    "                     param_distributions=params_NB,\n",
    "                     cv=cv_method,\n",
    "                     verbose=1,\n",
    "                     scoring='accuracy')\n",
    "\n",
    "# Data_transformed = PowerTransformer().fit_transform(X_pca_test)\n",
    "gs_NB.fit(X_pca_train, Y_pca_train)\n",
    "end = time.time()\n",
    "elapsed = end - st\n",
    "print(\"elapsed time\", elapsed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gs_NB.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gs_NB.best_score_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# gs_NB.fit(X_pca_train, Y_pca_train)\n",
    "Y_pca_pred = gs_NB.predict(X_pca_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(Y_pca_test, Y_pca_pred, zero_division=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(gs_NB, 'gaussian_nb_tuned.joblib')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ensembling - Bagging\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "st = time.time()\n",
    "\n",
    "ensemble_model = BaggingClassifier(estimator=gs_NB, n_estimators=50)\n",
    "\n",
    "ensemble_model.fit(X_pca_train, Y_pca_train)\n",
    "ensemble_model.fit(X_pca_val, Y_pca_val)\n",
    "Y_bag_pred = ensemble_model.predict(X_pca_test)\n",
    "end = time.time()\n",
    "\n",
    "print(classification_report(Y_pca_test, Y_bag_pred, zero_division=0))\n",
    "print(\"time: \", end - st)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ensembling - Boosting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "st = time.time()\n",
    "\n",
    "ensemble_model = AdaBoostClassifier(estimator=gs_NB, n_estimators=50)\n",
    "\n",
    "ensemble_model.fit(X_pca_train, Y_pca_train)\n",
    "ensemble_model.fit(X_pca_val, Y_pca_val)\n",
    "Y_bag_pred = ensemble_model.predict(X_pca_test)\n",
    "end = time.time()\n",
    "\n",
    "print(classification_report(Y_pca_test, Y_bag_pred, zero_division=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
